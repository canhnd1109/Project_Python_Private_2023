import math
from fractions import Fraction
from io import BytesIO

import cv2
import numpy as np
import pandas as pd
from PIL import Image, ImageEnhance, ImageFilter
from rembg import remove
import streamlit as st
from streamlit_image_coordinates import streamlit_image_coordinates


current_page = st.sidebar.radio("", ["üëãHello", "feature", "feedback"])

if current_page == "üëãHello":
    st.title('·ª®ng d·ª•ng ch·ªânh s·ª≠a ·∫£nh')
    st.image('image.jpg', use_column_width=True)

if current_page == "feature":
    # ƒê·ªçc ·∫£nh
    def load_image(uploaded_file):
        image = Image.open(uploaded_file)
        return image

    # Hi·ªÉn th·ªã ·∫£nh
    def show_image(image, key):
        img_array = np.array(image)  # Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ PIL Image sang NumPy array
        if len(img_array.shape) == 3:  # N·∫øu ·∫£nh c√≥ 3 chi·ªÅu (c√≥ k√™nh m√†u)
            height, width, _ = img_array.shape
        elif len(img_array.shape) == 2:  # N·∫øu ·∫£nh ch·ªâ c√≥ 2 chi·ªÅu (·∫£nh x√°m)
            height, width = img_array.shape
        else:
            st.error("Kh√¥ng th·ªÉ hi·ªÉn th·ªã ·∫£nh v·ªõi s·ªë chi·ªÅu kh√¥ng h·ª£p l·ªá.")
            return

        k = width / height
        value = streamlit_image_coordinates(image, key=key, width=300)
        if value is not None:
            st.write('x = {}, y = {}'.format(value['x'] * width / 300, value['y'] * height * k / 300))
        else:
            st.write('')

            
    # Hi·ªÉn th·ªã m·ªôt s·ªë th√¥ng tin ·∫£nh
    def show_info(image):
        
        img_array = np.array(image) # Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ PIL Image sang NumPy array

        height, width, _ = img_array.shape
        st.sidebar.write(f"K√≠ch th∆∞·ªõc: {width, height}")
        st.sidebar.write(f'T·ªâ l·ªá: {Fraction(width,height)}')
    
    # Code ph·∫ßn c√¥ng c·ª• ch·ªânh ·∫£nh
    # C·∫Øt theo ƒëi·ªÉm
    def crop_by_points(image, x1, y1, x2, y2):
        
        img_array = np.array(image) # Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ PIL Image sang NumPy array

        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # Chuy·ªÉn ƒë·ªïi x1, y1, x2, y2 sang ki·ªÉu s·ªë nguy√™n

        crop_by_points = img_array[y1:y2, x1:x2]

        return crop_by_points
    
    def crop_by_ellipse(image, center_x, center_y, major_axis, minor_axis):
        
        img_array = np.array(image)
        height, width, _ = img_array.shape

        mask = np.zeros((height, width), dtype=np.uint8) # T·∫°o m·ªôt m·∫£ng ch·ª©a ƒëi·ªÉm ·∫£nh tr·∫Øng

        cv2.ellipse(mask, (center_x, center_y), (major_axis, minor_axis), 0, 0, 360, 255, thickness=-1) # V·∫Ω ellipse tr·∫Øng l√™n mask

        result = cv2.bitwise_and(img_array, img_array, mask=mask) # √Åp d·ª•ng mask l√™n ·∫£nh g·ªëc ƒë·ªÉ c·∫Øt ·∫£nh theo ellipse

        crop_by_ellipse = Image.fromarray(result) # Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ sang ƒë·ªãnh d·∫°ng PIL Image

        return crop_by_ellipse

    # Ch·ª©c nƒÉng xoay ·∫£nh
    def rotate_image(image, angle):

        img_array = np.array(image)
        if angle == 90:
            rotated_image = cv2.rotate(img_array, cv2.ROTATE_90_CLOCKWISE)
        elif angle == 270:
            rotated_image = cv2.rotate(img_array, cv2.ROTATE_90_COUNTERCLOCKWISE)
        else:
            # T√≠nh to√°n k√≠ch th∆∞·ªõc m·ªõi cho ·∫£nh xoay
            img_array = np.array(image)
            height, width, _ = img_array.shape
            
            # T√≠nh to√°n k√≠ch th∆∞·ªõc m·ªõi d·ª±a tr√™n h√¨nh ch·ªØ nh·∫≠t bao quanh ·∫£nh xoay
            new_height = int(abs(width * math.sin(math.radians(angle))) + abs(height * math.cos(math.radians(angle))))
            new_width = int(abs(height * math.sin(math.radians(angle))) + abs(width * math.cos(math.radians(angle))))
            
            # T√≠nh to√°n ma tr·∫≠n bi·∫øn ƒë·ªïi ƒë·ªÉ th·ª±c hi·ªán xoay ·∫£nh
            center = (width // 2, height // 2)
            rotation_matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
            
            # Thay ƒë·ªïi k√≠ch th∆∞·ªõc c·ªßa ·∫£nh xoay ƒë·ªÉ kh√¥ng b·ªã c·∫Øt g√≥c
            rotation_matrix[0, 2] += (new_width - width) // 2
            rotation_matrix[1, 2] += (new_height - height) // 2
            
            rotated_img_array = cv2.warpAffine(img_array, rotation_matrix, (new_width, new_height))
            
            rotated_image = Image.fromarray(rotated_img_array)  # Chuy·ªÉn ƒë·ªïi l·∫°i sang ƒë·ªãnh d·∫°ng PIL Image

        return rotated_image

    # Ch·ª©c nƒÉng zoom ·∫£nh
    def zoom_image(image, zoom_factor, coordinates):
        img_array = np.array(image)
        height, width, _ = img_array.shape
        
        # T√≠nh to√°n ma tr·∫≠n bi·∫øn ƒë·ªïi ƒë·ªÉ th·ª±c hi·ªán zoom
        zoom_matrix = cv2.getRotationMatrix2D(coordinates, 0, zoom_factor)
        zoomed_img_array = cv2.warpAffine(img_array, zoom_matrix, (width, height))

        zoomed_image = Image.fromarray(zoomed_img_array) # Chuy·ªÉn ƒë·ªïi l·∫°i sang ƒë·ªãnh d·∫°ng PIL Image

        return zoomed_image

    # Ch·ª©c nƒÉng thay ƒë·ªïi t·ªâ l·ªá ·∫£nh
    def resize_image(image, aspect_ratio):

        img_array = np.array(image)

        height, width, _ = img_array.shape

        aspect_fraction = Fraction(aspect_ratio) # Bi·∫øn ƒë·ªïi t·ªâ l·ªá th√†nh d·∫°ng ph√¢n s·ªë
        
        # T√≠nh to√°n chi·ªÅu r·ªông m·ªõi d·ª±a tr√™n t·ªâ l·ªá mong mu·ªën
        new_width = int(height * aspect_fraction.numerator / aspect_fraction.denominator)
        
        # Th·ª±c hi·ªán thay ƒë·ªïi k√≠ch th∆∞·ªõc
        resized_img_array = cv2.resize(img_array, (new_width, height))

        # Chuy·ªÉn ƒë·ªïi l·∫°i sang ƒë·ªãnh d·∫°ng PIL Image
        resized_image = Image.fromarray(resized_img_array)
        return resized_image

    # Ch·ª©c nƒÉng l·∫≠t ·∫£nh
    def flip_bottom(image, dimension):
        img_array = np.array(image)
        flipped_image = cv2.flip(img_array, dimension)
        return Image.fromarray(flipped_image)
    
    # Code ph·∫ßn ƒëi·ªÅu ch·ªânh ·∫£nh                                  
    # ƒê·ªô s√°ng
    def adjust_image_gamma_lookuptable(image, gamma=1.0):
        # Chuy·ªÉn ƒë·ªïi image th√†nh m·∫£ng NumPy
        img_array = np.array(image)

        # T√≠nh to√°n b·∫£ng lookup
        table = np.array([(1.0 - (1.0 - i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")

        # √Åp d·ª•ng gamma correction s·ª≠ d·ª•ng b·∫£ng lookup
        adjusted_img_array = cv2.LUT(img_array, table)

        # Chuy·ªÉn ƒë·ªïi l·∫°i sang ƒë·ªãnh d·∫°ng PIL Image
        adjusted_image = Image.fromarray(adjusted_img_array)

        return adjusted_image

    # ƒê·ªô ·∫•m
    def adjust_temperature(image, factor):
        
        
        enhancer = ImageEnhance.Color(image) # T·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng Enhancer cho Temperature
        image_with_temperature = enhancer.enhance(factor) # √Åp d·ª•ng hi·ªáu ·ª©ng Temperature
        
        return (image_with_temperature)
        
    # ƒê·ªô t∆∞∆°ng ph·∫£n
    def adjust_contrast(image, contrast_factor):
        enhancer = ImageEnhance.Contrast(image)
        adjusted_image = enhancer.enhance(contrast_factor)
        return adjusted_image
    
    # ƒê·ªô b√£o h√≤a
    def adjust_saturation(image, saturation_factor):
        enhancer = ImageEnhance.Color(image)
        adjusted_image = enhancer.enhance(saturation_factor)
        return adjusted_image
    
    # Hi·ªáu ·ª©ng ·∫£nh x√°m
    def gray_Image(image):
        converted_img = np.array(image.convert('RGB'))
        gray_scale = cv2.cvtColor(converted_img, cv2.COLOR_RGB2GRAY)
        return gray_scale
    
    # ·∫¢nh ƒëen tr·∫Øng
    def Black_and_White(image, slider):
        converted_img = np.array(image.convert('RGB'))
        gray_scale = cv2.cvtColor(converted_img, cv2.COLOR_RGB2GRAY)
        (thresh, blackAndWhiteImage) = cv2.threshold(gray_scale, slider, 255, cv2.THRESH_BINARY)
        return blackAndWhiteImage
    
    # Ph√°c th·∫£o b√∫t ch√¨
    def Pencil_Sketch(image, slider):
        converted_img = np.array(image.convert('RGB')) 
        gray_scale = cv2.cvtColor(converted_img, cv2.COLOR_RGB2GRAY)
        inv_gray = 255 - gray_scale
        blur_image = cv2.GaussianBlur(inv_gray, (slider,slider), 0, 0)
        sketch = cv2.divide(gray_scale, 255 - blur_image, scale=256)
        return sketch
    
    # L√†m m·ªù ·∫£nh
    def Blur_Effect(image, slider):
        converted_img = np.array(image.convert('RGB'))
        # converted_img = cv2.cvtColor(converted_img, cv2.COLOR_RGB2BGR)
        blur_image = cv2.GaussianBlur(converted_img, (slider,slider), 0, 0)
        return blur_image
    
    # L√†m m·ªãn ·∫£nh
    def Smooth_Effect(image, slider):
        converted_img = np.array(image.convert('RGB'))
        kernel = np.ones((slider, slider), np.float32) / (slider ** 2) # T·∫°o kernel l√†m m·ªãn
        smoothed_image = cv2.filter2D(converted_img, -1, kernel) # L√†m m·ªãn ·∫£nh b·∫±ng filter2D
        return smoothed_image
    
    def process_logo_contour(image):
        convert_image = (image.convert('L'))
        threshold = 50
        convert_image = convert_image.point(lambda x: 255 if x > threshold else 0)

        # √Åp d·ª•ng b·ªô l·ªçc Contour
        convert_image = convert_image.filter(ImageFilter.CONTOUR)
        return convert_image
    
    # H√†m chuy·ªÉn ƒë·ªïi t·ª´ m√£ m√†u hex sang tuple BGR
    def hex_to_bgr(hex_color):
        hex_color = hex_color.lstrip('#')
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))
    
    # Ch√®n ch·ªØ l√™n ·∫£nh
    def add_text_to_image(image, text, position, font_scale, font_color, font_thickness):
        img_array = np.array(image)

        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(img_array, text, position, font, font_scale, hex_to_bgr(font_color), font_thickness, cv2.LINE_AA)

        return Image.fromarray(img_array)

    # X√≥a ph√¥ng
    def image_bg_remover(image):
        fixed = remove(image)
        return fixed
    
    def convert_image(img):
        if isinstance(img, np.ndarray):
            img = Image.fromarray(img) # N·∫øu img l√† NumPy array, chuy·ªÉn ƒë·ªïi th√†nh ƒë·ªëi t∆∞·ª£ng Image
            
        buf = BytesIO()
        img.save(buf, format="PNG")
        byte_im = buf.getvalue()
        return byte_im

    # √Åp d·ª•ng c√¥ng c·ª• v√† hi·ªÉn th·ªã ·∫£nh
    def apply_tools(image, selected_tools):
    
        # C·∫Øt ·∫£nh
        if "C·∫Øt ·∫£nh" in selected_tools:
            crop_options = st.sidebar.radio("Ch·ªçn ki·ªÉu c·∫Øt ·∫£nh", ["C·∫Øt theo h√¨nh ch·ªØ nh·∫≠t", "C·∫Øt theo ellipse"])
            
            if crop_options == "C·∫Øt theo h√¨nh ch·ªØ nh·∫≠t":
                x1 = st.sidebar.number_input('Nh·∫≠p x1:',min_value=0, value= image.width//4, help='Nh·∫≠p t·ªça ƒë·ªô x c·ªßa ƒëi·ªÉm tr√™n b√™n tr√°i')
                y1 = st.sidebar.number_input('Nh·∫≠p y1:', min_value=0, value= image.height//4, help='Nh·∫≠p t·ªça ƒë·ªô y c·ªßa ƒëi·ªÉm tr√™n b√™n tr√°i')
                x2 = st.sidebar.number_input('Nh·∫≠p x2:', min_value=1, value= image.width//2, help='Nh·∫≠p t·ªça ƒë·ªô x c·ªßa ƒëi·ªÉm d∆∞·ªõi b√™n ph·∫£i')
                y2 = st.sidebar.number_input('Nh·∫≠p y2:', min_value=1, value= image.height//2, help='Nh·∫≠p t·ªça ƒë·ªô y c·ªßa ƒëi·ªÉm d∆∞·ªõi b√™n ph·∫£i')
                
                # C·∫Øt ·∫£nh theo ƒëi·ªÉm
                image = crop_by_points(image, x1, y1, x2, y2)
                
            if crop_options == "C·∫Øt theo ellipse":
                center_x = st.sidebar.number_input("T·ªça ƒë·ªô trung t√¢m X", min_value=0, max_value=image.width, value=image.width // 2)
                center_y = st.sidebar.number_input("T·ªça ƒë·ªô trung t√¢m Y", min_value=0, max_value=image.width, value=image.width // 2)
                major_axis = st.sidebar.number_input("Tr·ª•c Ch√≠nh", min_value=1, max_value=min(image.width, image.height), value=image.width // 3)
                minor_axis = st.sidebar.number_input("Tr·ª•c Ph·ª•", min_value=1, max_value=min(image.width, image.height), value=image.width // 6)

                # C·∫Øt ·∫£nh theo ellipse
                image = crop_by_ellipse(image, center_x, center_y, major_axis, minor_axis)    
            
        # Xoay ·∫£nh
        if "Xoay ·∫£nh" in selected_tools:
            rotation_angle = st.sidebar.slider("G√≥c Xoay", 0, 360, 0, help='K√©o thanh tr∆∞·ª£t ƒë·ªÉ ch·ªânh g√≥c quay')
            image = rotate_image(image, rotation_angle)

        # Zoom ·∫£nh
        if "Zoom" in selected_tools:
            zoom_factor = st.sidebar.slider("T·ªâ l·ªá Zoom", 0.0, 5.0, 1.0,
                                           help='K√©o thanh tr∆∞·ª£t ƒë·ªÉ ch·ªânh t·ªâ l·ªá ph√≥ng to hay thu nh·ªè ·∫£nh')
            x = st.sidebar.number_input('Nh·∫≠p t·ªça ƒë·ªô x')
            y = st.sidebar.number_input('Nh·∫≠p t·ªça ƒë·ªô y')
            coordinates = (x, y)
            image = zoom_image(image, zoom_factor, coordinates)

        if "Thay ƒë·ªïi t·ªâ l·ªá ·∫£nh" in selected_tools:
            st.sidebar.subheader("Ch·ªçn T·ªâ L·ªá ·∫¢nh")
            aspect_ratio = st.sidebar.selectbox("Ch·ªçn t·ªâ l·ªá ·∫£nh",
                                               ['9/16', '2/3', '3/4', '1', '4/3', '3/2', '16/9'],
                                               help='L·ª±a ch·ªçn t·ªâ l·ªá m·ªõi cho b·ª©c ·∫£nh c·ªßa b·∫°n')
            image = resize_image(image, aspect_ratio)
            
        if "L·∫≠t ·∫£nh" in selected_tools:
            options=st.sidebar.selectbox("Ch·ªçn ki·ªÉu l·∫≠t", ["Chi·ªÅu d·ªçc", "Chi·ªÅu ngang"])
            d = 0
            if "Chi·ªÅu ngang" in options:
                d = 1
            image = flip_bottom(image, d)
            
        if "ƒê·ªô s√°ng" in selected_tools:
            gamma_value = st.sidebar.slider("Ch·ªçn ƒë·ªô s√°ng", 0.0, 10.0, 5.0, 0.5, help="K√©o thanh tr∆∞·ª£t ƒë·ªÉ ch·ªânh ƒë·ªô s√°ng")
            image = adjust_image_gamma_lookuptable(image, gamma_value/5)
            
        if "ƒê·ªô ·∫•m" in selected_tools:
            factor = st.sidebar.slider("Chon ƒë·ªô ·∫•m", 0.0, 10.0, 5.0, 0.5, help="K√©o thanh tr∆∞·ª£t ƒë·ªÉ ch·ªânh ƒë·ªô ·∫•m")
            image = adjust_temperature(image, factor/5)
        
        if "ƒê·ªô t∆∞∆°ng ph·∫£n" in selected_tools:
            contrast_factor = st.sidebar.slider("Ch·ªçn ƒê·ªô T∆∞∆°ng Ph·∫£n", 0.0, 10.0, 5.0, 0.5, help="K√©o thanh tr∆∞·ª£t ƒë·ªÉ ch·ªânh ƒë·ªô t∆∞∆°ng ph·∫£n")
            image = adjust_contrast(image, contrast_factor/5)
        
        if "ƒê·ªô b√£o h√≤a" in selected_tools:
            saturation_factor = st.sidebar.slider("Ch·ªçn ƒë·ªô b√£o h√≤a", 0.0, 10.0, 5.0, 0.5, help="K√©o thanh tr∆∞·ª£t ƒë·ªÉ ch·ªânh ƒë·ªô b√£o h√≤a")
            image = adjust_saturation(image, saturation_factor/5)
            
        if "Original" in selected_tools:
            image = image
        
        if "Gray Image" in selected_tools:
            image = gray_Image(image)
            
        if "Black and White" in selected_tools:
            slider = st.sidebar.slider("ƒêi·ªÅu ch·ªânh c∆∞·ªùng ƒë·ªô", 1, 255, 127, 1)
            image = Black_and_White(image, slider)
        
        if "Pencil Sketch" in selected_tools:
            slider = st.sidebar.slider("ƒêi·ªÅu ch·ªânh c∆∞·ªùng ƒë·ªô", 5, 255, 125, 2)
            image = Pencil_Sketch(image, slider)
            
        if "Blur Effect" in selected_tools:
            slider = st.sidebar.slider("ƒêi·ªÅu ch·ªânh ƒë·ªô m·ªù", 5, 125, 15, 2)
            image = Blur_Effect(image, slider)
            
        if "Smooth Effect" in selected_tools:
            slider = st.sidebar.slider("ƒêi·ªÅu ch·ªânh ƒë·ªô m·ªãn", 1, 10, 5, 1)
            image = Smooth_Effect(image, slider)
        
        if "process_logo_contour" in selected_tools:
            image = process_logo_contour(image)
        
        if "Ch√®n ch·ªØ" in selected_tools:
            text_to_add = st.sidebar.text_input("Nh·∫≠p vƒÉn b·∫£n", value="HIT")
            position_x = st.sidebar.slider("V·ªã tr√≠ X", 0, image.width, image.width // 2)
            position_y = st.sidebar.slider("V·ªã tr√≠ Y", 0, image.height, image.height // 2)

            font_scale = st.sidebar.slider("C·ª° ch·ªØ", 1.0, 40.0, 8.0, 1.0)
            font_color = st.sidebar.color_picker("M√†u ch·ªØ", "#FF5733")
            font_thickness = st.sidebar.slider("ƒê·ªô ƒë·∫≠m c·ªßa ch·ªØ", 1, 10, 2)

            image = add_text_to_image(image, text_to_add, (position_x, position_y), font_scale, font_color, font_thickness)
        
        if "X√≥a ph√¥ng" in selected_tools:
            image = image_bg_remover(image)
            
        return image

    def main():
        st.title("·ª®ng D·ª•ng Ch·ªânh S·ª≠a ·∫¢nh")
        uploaded_file = None
        # Ch·ªçn ·∫£nh t·ª´ m√°y t√≠nh
        image_source = st.radio('Ch·ªçn ngu·ªìn ·∫£nh', ['Webcam', 'Ch·ªçn ·∫£nh t·ª´ m√°y'])
        if image_source == 'Webcam':
            uploaded_file = st.camera_input('Ch·ª•p ·∫£nh t·ª´ webcam')
        else:
            uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh...", type=["jpg", "png", "jpeg"])

        if uploaded_file is not None:

            col1, col2 = st.columns([1, 1])
            with col1:
                # ƒê·ªçc ·∫£nh v√† hi·ªÉn th·ªã ·∫£nh g·ªëc
                original_image = load_image(uploaded_file)
                show_image(original_image, key='original_image')

                show_info(original_image)

            st.sidebar.title("Ch·ªçn Ch·ª©c NƒÉng")

            # T·∫°o containers cho t·ª´ng lo·∫°i c√¥ng c·ª•, hi·ªáu ·ª©ng v√† ƒëi·ªÅu ch·ªânh
            with st.sidebar.container():
                selected_functions = st.multiselect("Ch·ªçn ch·ª©c nƒÉng", ["C√¥ng c·ª•", "ƒêi·ªÅu ch·ªânh", "Hi·ªáu ·ª©ng", "Ch·ªØ", "X√≥a ph√¥ng"])
                selected_tools_1 = []
                selected_tools_2 = []
                selected_tools_3 = []
                selected_tools_4 = []
                selected_tools_5 = []
                selected_tools_6 = []
                
                if "C√¥ng c·ª•" in selected_functions:
                    selected_tools_1 = st.multiselect("Ch·ªçn c√¥ng c·ª•", ["C·∫Øt ·∫£nh", "Xoay ·∫£nh", "Zoom", "Thay ƒë·ªïi t·ªâ l·ªá ·∫£nh", "L·∫≠t ·∫£nh"])
                
                if "ƒêi·ªÅu ch·ªânh" in selected_functions:
                    selected_tools_2 = st.multiselect("ƒêi·ªÅu ch·ªânh", ["ƒê·ªô s√°ng", "ƒê·ªô ·∫•m", "ƒê·ªô t∆∞∆°ng ph·∫£n", "ƒê·ªô b√£o h√≤a"])
                
                if "Hi·ªáu ·ª©ng" in selected_functions:
                    selected_tools_3 = st.radio("filters", ["Original", "Gray Image", "Black and White", "Pencil Sketch", "Blur Effect", "Smooth Effect", "process_logo_contour"])
                
                if "Ch·ªØ" in selected_functions:
                    selected_tools_4 = st.radio("", ["Ch√®n ch·ªØ"])
                    
                if "X√≥a ph√¥ng" in selected_functions:
                    selected_tools_6 = st.radio("", ["X√≥a ph√¥ng"])

                # G·ªôp danh s√°ch c√¥ng c·ª• ƒë√£ ch·ªçn
                selected_tools = selected_tools_1 + selected_tools_2 + [selected_tools_3] + [selected_tools_4] + [selected_tools_5] + [selected_tools_6]

            with col2:
                # √Åp d·ª•ng c√°c c√¥ng c·ª• v√† hi·ªÉn th·ªã ·∫£nh sau khi √°p d·ª•ng
                edited_image = apply_tools(original_image.copy(), selected_tools)
                if selected_tools:
                    show_image(edited_image, key='edited_image')
                    
            st.sidebar.download_button("T·∫£i ·∫£nh", convert_image(edited_image), "new_image.png", "image/png")
                    
    if __name__ == "__main__":
        main()

if current_page == "feedback":

    def feed_back():
        # ƒê·ªçc d·ªØ li·ªáu hi·ªán t·∫°i t·ª´ t·ªáp vƒÉn b·∫£n (n·∫øu c√≥)
        try:
            feedback_data = pd.read_csv('feedback_data.csv')
        except FileNotFoundError:
            # N·∫øu t·ªáp kh√¥ng t·ªìn t·∫°i, t·∫°o DataFrame m·ªõi
            feedback_data = pd.DataFrame(
                columns=['Name', 'Age', 'Address', 'PhoneNumber', 'Link FB', 'Rating', 'Feedback'])
            feedback_data.to_csv('feedback_data.csv', index=False)

        st.subheader('Xin h√£y gi√∫p ch√∫ng t√¥i c·∫£i thi·ªán!')
        with st.form(key='columns_in_form', clear_on_submit=True):
            name = st.text_input("T√™n ƒë·∫ßy ƒë·ªß", help='ƒêi·ªÅn h·ªç v√† t√™n c·ªßa b·∫°n')
            age = st.text_input('Tu·ªïi', help='ƒêi·ªÅn tu·ªïi c·ªßa b·∫°n')
            phonenumber = st.text_input('S·ªë ƒëi·ªán tho·∫°i', help='ƒêi·ªÅn s·ªë ƒëi·ªán tho·∫°i')
            address = st.text_input('ƒê·ªãa ch·ªâ', help='Cho xin c√°i t·ªça ƒë·ªô))')
            linkFB = st.text_input('Link FB', help='Cho xin in4 ƒë√™ :>')
            rating = st.slider("ƒê√°ng gi√° app", min_value=1, max_value=10, value=1,
                               help='K√©o thanh tr∆∞·ª£t ƒë·ªÉ x·∫øp h·∫°ng ·ª©ng d·ª•ng. ƒê√¢y l√† thang ƒë√°nh gi√° t·ª´ 1 ƒë·∫øn 10 trong ƒë√≥ 10 l√† m·ª©c ƒë√°nh gi√° cao nh·∫•t')
            text = st.text_input(label='Xin h√£y ƒë·ªÉ l·∫°i th√¥ng tin ph·∫£n h·ªìi c·ªßa b·∫°n t·∫°i ƒë√¢y')
            submitted = st.form_submit_button('G·ª≠i')
            if submitted:
                st.write('C·∫£m ∆°n ƒë√£ ƒë·ªÉ l·∫°i ƒë√°nh gi√°!')

                # L∆∞u th√¥ng tin ƒë√°nh gi√° v√†o DataFrame
                new_feedback = pd.DataFrame(
                    {'Name': [name], 'Age': [age], 'PhoneNumber': [phonenumber], 'Address': [address], 'Link FB': [linkFB],
                     'Rating': [rating], 'Feedback': [text]})
                feedback_data = pd.concat([feedback_data, new_feedback], ignore_index=True)

                # L∆∞u DataFrame v√†o t·ªáp vƒÉn b·∫£n
                feedback_data.to_csv('feedback_data.csv', index=False)

    if __name__ == "__main__":
        feed_back()
